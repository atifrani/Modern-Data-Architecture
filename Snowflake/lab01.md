# Lab 1 ‚Äî Introduction √† Snowflake (Pas-√†-pas)

> **Objectif**  
D√©couvrir l‚Äôinterface Snowflake, cr√©er les premiers objets (DB, table, stage, formats de fichier), **charger des donn√©es CSV depuis S3**, explorer/optimiser le chargement, puis **charger des donn√©es JSON** et les joindre aux donn√©es structur√©es. √Ä la fin, vous saurez charger vos propres donn√©es et ex√©cuter des requ√™tes simples.

---

## 0) Pr√©requis

- Compte Snowflake d‚Äôessai (**√©tudiants : 120 jours**) ‚Äì inscrivez-vous avec l‚Äôadresse **de l‚Äô√©cole**, soci√©t√© **MBAESG**, r√¥le **√âtudiant**, **Edition : Enterprise**, **Cloud : AWS**, **R√©gion : us-west-2**.
- lien pour cr√©er votre compte:  https://signup.snowflake.com/?trial=student&cloud=aws&region=us-west-2&utm_source=handsonessentials&utm_campaign=uni-dww# 
- Bases de SQL (DDL/DML) et objets (database, schema, table‚Ä¶).  
- Connaissance des formats **CSV** et **JSON**.

> **Bon √† savoir ‚Äì Cr√©dits**  
Conservez **Auto-Suspend** activ√© et utilisez une **taille d‚Äôentrep√¥t raisonnable** pour √©viter d‚Äô√©puiser vos cr√©dits.  

## 1) Connexion & tour rapide de l‚ÄôUI

1. Ouvrez l‚ÄôURL re√ßue par email et connectez-vous.  
2. Onglets utiles :
   - **Worksheets** : √©crire/ex√©cuter du SQL, voir les **Results/Query/Graph**.
   - **Data ‚Ä∫ Databases** : g√©rer DB/schemas/tables, chargement via UI.
   - **Dashboards** : cr√©er des graphiques √† partir de requ√™tes.
   - **Activity ‚Ä∫ Query History / Copy History** : historiser ex√©cutions/chargements.
   - **Admin ‚Ä∫ Warehouses** : cr√©er/configurer les **entrep√¥ts virtuels** (compute).
   - **Admin ‚Ä∫ Users & Roles** : r√¥les et hi√©rarchies.
3. Dans une **Worksheet**, v√©rifiez la **Context Box** (r√¥le, warehouse, DB, schema) et le bouton **Run**.


## 2) Pr√©parer l‚Äôenvironnement de travail

> Dans ce lab nous utiliserons le r√¥le **ACCOUNTADMIN** pour simplifier (en production, privil√©giez le principe du moindre privil√®ge).

1. Ouvrez **Worksheets**.
2. **Contexte de session** (en haut de la feuille) :  
   - **Role** : `ACCOUNTADMIN`  
   - **Warehouse** : `COMPUTE_WH` (par d√©faut de l‚Äôessai)  

## 3) Cr√©er une base de donn√©es

Dans Snowflake, une **base de donn√©es** regroupe plusieurs **sch√©mas et objets** (tables, vues, stages...).

üëâ Ex√©cutez la commande suivante dans votre feuille de calcul :

```sql
-- Cr√©e ou remplace la base de donn√©es 'MYDB'

create or replace database MYDB;
```

```sql
-- Liste les bases de donn√©es disponibles

show databases;
```

```sql
-- Cr√©e ou remplace le sch√©ma 'HR' dans la base 'MYDB'

create or replace schema HR;
```

```sql
-- d√©finir le context

use database MYDB;

use schema HR;
```

## 4) Cr√©er une table structur√©e (donn√©es tabulaires)

Nous allons cr√©er une table EMPLOYEES avec des colonnes typ√©es.

```sql
-- Cr√©ation de la table EMPLOYEES
create or replace table EMPLOYEES
(
    emp_id      varchar,
    fname       varchar,
    lname       varchar,
    address     varchar,
    city        varchar,
    state       varchar,
    zipcode     int,
    job_title   varchar,
    email       varchar,
    active      boolean,
    salary      int
);
```

```sql
-- V√©rifier que la table est bien cr√©e

show tables in schema HR;

select * from EMPLOYEES;
```

## 5) Chager les donn√©es manuellement depuis l'UI

![alt text](../images/snow1.png)

![alt text](../images/snow2.png)

![alt text](../images/snow3.png)

![alt text](../images/snow4.png)

![alt text](../images/snow5.png)

```sql
-- Afficher les donn√©es

select * from EMPLOYEES;
```

## 6) Cr√©er une table pour stocker des donn√©es JSON

Snowflake permet de stocker des donn√©es semi-structur√©es (JSON, Parquet, etc.) via le type VARIANT.

```sql
-- Table pour stocker des documents JSON

create or replace table EMPLOYEES_JSON
(
    data variant
);
```

```sql
-- V√©rifier que la table est bien cr√©e

show tables in schema HR;
select * from EMPLOYEES_JSON;
```

## 7) Chager les donn√©es manuellement depuis l'UI

![alt text](../images/snow1.png)

![alt text](../images/snow2.png)

![alt text](../images/snow3.png)

![alt text](../images/snow4.png)

![alt text](../images/snow5.png)

```sql
-- afficher les donn√©es

select * from EMPLOYEES_JSON;
```

## 8) Cr√©er une vue sur les donn√©es JSON
Nous allons cr√©er une vue pour extraire des champs sp√©cifiques depuis le JSON stock√© dans la table EMPLOYEES_JSON.
Cela permet d‚Äôexposer les donn√©es semi-structur√©es sous forme tabulaire.

```sql
-- Vue pour extraire des champs JSON sous forme tabulaire

create or replace view EMPLOYEES_CSV as
select 
    data:"birth-date"   as "birth-date",
    data:"first-name"   as "first-name",
    data:"job-title"    as "job-title",
    data:"last-name"    as "last-name",
    data:"location"     as "location"
from EMPLOYEES_JSON;
```

```sql
-- Afficher les donn√©es
select * from EMPLOYEES_CSV;
```

## üéØ R√©sum√©

Dans ce lab, vous avez appris √† :

* Cr√©er une base de donn√©es et un sch√©ma dans Snowflake.

* D√©finir des tables structur√©es et semi-structur√©es.

* Cr√©er une vue sur des donn√©es JSON.

* Naviguer et interroger les objets via la Snowflake UI.


## CITIBIKE Use Case:

**Contexte**

Citi Bike est le syst√®me de v√©los en libre-service de la ville de New York, et l‚Äôun des plus grands au monde.
L‚Äôobjectif de cet exercice est d‚Äôanalyser les donn√©es d‚Äôutilisation afin de r√©pondre √† plusieurs questions cl√©s que se pose l‚Äôentreprise :

* O√π les usagers de Citi Bike se d√©placent-ils ?

* √Ä quels moments de la journ√©e roulent-ils le plus ?

* Quelles distances parcourent-ils en moyenne ?

* Quelles stations sont les plus fr√©quent√©es ?

* Et quels jours de la semaine enregistrent le plus grand nombre de trajets ?

Cette analyse permettra de mieux comprendre les habitudes de d√©placement des utilisateurs et d‚Äôidentifier les tendances d‚Äôutilisation du service.

1. Ouvrez **Worksheets** et renommez la feuille en `CITIBIKE.sql`.
2. **Contexte de session** (en haut de la feuille) :  
   - **Role** : `ACCOUNTADMIN`  
   - **Warehouse** : `COMPUTE_WH` (par d√©faut de l‚Äôessai)  
   - Nous cr√©erons la base et s√©lectionnerons DB/Schema ensuite.

## 1) Cr√©er la base et la table `TRIPS` (CSV Citi Bike)

1. **Cr√©er la database** `CITIBIKE` puis s√©lectionner le contexte :

   ```sql

   create or replace database CITIBIKE;

   use database CITIBIKE;

   use schema PUBLIC;

   ```

2. **Cr√©er la table** `TRIPS` :

   ```sql
   create or replace table TRIPS (
     tripduration integer,
     starttime timestamp,
     stoptime timestamp,
     start_station_id integer,
     start_station_name string,
     start_station_latitude float,
     start_station_longitude float,
     end_station_id integer,
     end_station_name string,
     end_station_latitude float,
     end_station_longitude float,
     bikeid integer,
     membership_type string,
     usertype string,
     birth_year integer,
     gender integer
   );
   ```

## 2) Cr√©er le **Stage** externe (S3) & le **Format de fichier CSV**

> Les fichiers CSV Citi Bike sont d√©j√† publi√©s en lecture publique sur S3.

1. **Stage** (standardisez le nom : `citibike_trips`) :

   ```sql
   -- Stage public S3 (notez le / final)
   create or replace stage citibike_csv
     url='s3://logbrain-datalake/datasets/citibike-trips-csv/';
   ```

   > **Astuce** : pas d‚Äôidentifiants pour ce bucket public.

2. **Lister le contenu du stage** :

   ```sql
   list @citibike_csv;
   ```

3. **Format de fichier** `csv` :

   ```sql
   create or replace file format csv
     type = 'CSV'
     field_delimiter = ','
     record_delimiter = '\n'
     skip_header = 1
     field_optionally_enclosed_by = '\042'
     null_if = (''); 
   ```

4. **Contr√¥ler** :

   ```sql
   show file formats in database CITIBIKE;
   ```

## 5) Charger les donn√©es (COPY INTO) & mesurer l‚Äôimpact de la taille d‚Äôentrep√¥t

### 5.1 Premier chargement (entrep√¥t **Small**)

1. **(Optionnel)** redimensionner `COMPUTE_WH` en **Small** via Admin ‚Ä∫ Warehouses ou SQL :

   ```sql
   alter warehouse COMPUTE_WH set warehouse_size='SMALL';
   ```

2. **Contexte** :

   ```sql
   use role ACCOUNTADMIN;
   use warehouse COMPUTE_WH;
   use database CITIBIKE;
   use schema PUBLIC;
   ```

3. **Charger** :

   ```sql
   copy into TRIPS
   from @citibike_csv
   file_format = csv
   pattern = '.*\.csv.*';
   ```

4. **V√©rifier** : dans les **Results**, status par fichier + **Copy History** (Activity).


```sql
-- Affichez les donn√©es
select * from trips;

-- Compter le nombre de lignes
select count(*) from trips
```

### 5.2 Rechargement comparatif (entrep√¥t **LARGE**)

1. **Purge** :

   ```sql
   -- Vider la table

   truncate table TRIPS;
   ```

   V√©rifiez :

   ```sql
   select * from TRIPS limit 10;  -- aucun r√©sultat attendu
   ```

2. **Redimensionner** :

   ```sql
   alter warehouse COMPUTE_WH set warehouse_size='LARGE';
   show warehouses;
   ```

3. **Relancer le chargement** :

   ```sql
   copy into TRIPS
   from @citibike_trips
   file_format = csv
   pattern = '.*\.csv.*';
   ```

4. **Comparer** dans **Activity ‚Ä∫ Query History** : le chargement en LARGE doit √™tre plus rapide.

```sql
-- Affichez les donn√©es
select * from trips;

-- Compter le nombre de lignes
select count(*) from trips
```

> **Rappel** : remettez l‚Äôentrep√¥t √† une taille plus petite apr√®s vos tests si vous continuez √† travailler.

  ```sql
   alter warehouse COMPUTE_WH set warehouse_size='XSMALL';
   show warehouses;
   ```

## 6) Cr√©er un entrep√¥t d√©di√© **ANALYTICS_WH** (pour les requ√™tes)

1. **Cr√©er** :
   ```sql
   create or replace warehouse ANALYTICS_WH
     warehouse_size = 'LARGE'
     auto_suspend = 5
     auto_resume = true
     initially_suspended = true;
   ```
2. **Basculer le contexte** :
   ```sql
   use warehouse ANALYTICS_WH;
   ```

## 7) Ex√©cuter quelques requ√™tes analytiques

1. **Par heure : nb trajets, dur√©e et distance moyennes**  
   *(la fonction `HAVERSINE` calcule une distance g√©od√©sique approx. en km)*  
   ```sql
   select
     date_trunc('hour', starttime) as "Hour",
     count(*)                           as "num trips",
     avg(tripduration)/60               as "avg duration (mins)",
     avg(haversine(
       start_station_latitude, start_station_longitude,
       end_station_latitude,  end_station_longitude
     ))                                 as "avg distance (km)"
   from TRIPS
   group by 1
   order by 1;
   ```

   Relancez **exactement la m√™me requ√™te** et observez le **Result Cache** (retour instantan√©, sans cr√©dits).

2. **Jours de la semaine les plus charg√©s**

   ```sql
   select
     dayname(starttime) as "day of week",
     count(*)           as "num trips"
   from TRIPS
   group by 1
   order by 2 desc;
   ```

3. **Clone** de la table pour dev :
   ```sql
   create or replace table TRIPS_DEV clone TRIPS;
   ```

## 8) Donn√©es **JSON** (m√©t√©o NYC) : chargement & vue ¬´ colonnes ¬ª

1. **Table JSON (colonne VARIANT)** :
   ```sql
   create or replace table JSON_WEATHER_DATA (v variant);
   ```
2. **Stage S3 JSON** :
   ```sql
   create or replace stage NYC_WEATHER
     url='s3://logbrain-datalake/datasets/weather-nyc-json/';
   list @NYC_WEATHER;
   ```
3. **Chargement JSON** :
   ```sql
   copy into JSON_WEATHER_DATA
   from @NYC_WEATHER
   file_format = (type = json);
   ```
   V√©rifier :
   ```sql
   select * from JSON_WEATHER_DATA limit 10;
   ```
4. **Format JSON √† outer array** :
   ```sql
   create or replace file format json
     type = 'JSON'
     strip_outer_array = true;

   truncate table JSON_WEATHER_DATA;

   copy into JSON_WEATHER_DATA
   from @NYC_WEATHER
   file_format = json;
   ```
6. **Vue lisible** :
   
   ```sql
     create or replace table weather as
       select 
      v:"coco"::STRING as "coco" ,
      v:"country"::STRING as "country",
      v:"dwpt"::FLOAT as "dwpt",
      v:"elevation"::STRING as "elevation",
      v:"icao"::STRING as "icao",
      v:"latitude"::DECIMAL as "latitude",
      v:"longitude"::DECIMAL as "longitude",
      v:"name"::STRING as "name",
      v:"obsTime"::TIMESTAMP as "obsTime",
      v:"prcp"::STRING as "prcp" ,
      v:"pres"::DECIMAL as "pres",
      v:"region"::STRING as "region",
      v:"rhum"::STRING as "rhum",
      v:"snow"::STRING as "snow",
      v:"station"::STRING as "station",
      v:"temp"::DECIMAL "temp",
      v:"timezone"::STRING as "timezone",
      v:"tsun"::STRING as "tsun",
      v:"wdir"::STRING as "wdir",
      v:"weatherCondition"::STRING as "weatherCondition",
      v:"wmo"::STRING as "wmo",
      v:"wpgt"::STRING as "wpgt",
      v:"wspd"::DECIMAL as "wspd"
    from json_weather_data;
   ```
7. **Filtre d‚Äôexemple** :
   ```sql
   select *
   from WEATHER
   where date("obstime") = '2018-01-01'
   limit 20;
   ```

## 9) Corr√©ler m√©t√©o (JSON) & trajets (CSV)

On joint sur la **date** de l‚Äôobservation m√©t√©o et la **date de d√©part** du trajet.

```sql
use database CITIBIKE;  
use schema PUBLIC;
use warehouse ANALYTICS_WH;

select
  "weatherCondition",
  count(*) as num_trips
from CITIBIKE.PUBLIC.TRIPS
left join CITIBIKE.PUBLIC.WEATHER
  on date("obsTime") = date(starttime)
where "weatherCondition" is not null
group by 1
order by 2 desc;
```

## 10) Time-Travel : **Undrop** & **Rollback**

1. **Undrop d‚Äôune table supprim√©e** :
   ```sql
   use database CITIBIKE; 
   
   use schema PUBLIC;

   drop table JSON_WEATHER_DATA;

   -- V√©rification : doit renvoyer 0 ligne / erreur si vous requ√™tez
   select * from JSON_WEATHER_DATA limit 10;

   undrop table JSON_WEATHER_DATA;
   ```
2. **Rollback apr√®s une mise √† jour erron√©e** :

   ```sql
   use database CITIBIKE; 
   use schema PUBLIC;

   -- Erreur volontaire
   update TRIPS set start_station_name = 'oops';

   -- Retrouver l'ID de la derni√®re UPDATE
   set query_id = (
     select query_id
     from table(information_schema.query_history_by_session(result_limit=>5))
     where query_text ilike 'update%'
     order by start_time desc
     limit 1
   );

   -- Restaurer la table avant l'UPDATE
   create or replace table TRIPS as
   select * from TRIPS before (statement => $query_id);

   -- Re-v√©rifier
   select start_station_name as "station", count(*) as "rides"
   from TRIPS
   group by 1
   order by 2 desc
   limit 20;
   ```



## 11) (Bonus) Mini-app **Streamlit** dans Snowflake

### Introduction √† Streamlit

Avant de cr√©er notre mini-application connect√©e √† Snowflake, d√©couvrons rapidement **Streamlit**, un framework Python simple et puissant pour cr√©er des interfaces web interactives destin√©es √† la data science et √† l‚Äôanalyse de donn√©es.

Streamlit permet de transformer un **script Python** en application web en quelques lignes seulement, sans connaissances en d√©veloppement web.

* **Exemple 1 :** afficher du texte et des graphiques

```python
import streamlit as st
import pandas as pd

st.title("Exemple Streamlit : Visualisation simple")

# Cr√©er un petit DataFrame
data = pd.DataFrame({
    "Jour": ["Lundi", "Mardi", "Mercredi", "Jeudi", "Vendredi"],
    "Ventes": [100, 150, 90, 200, 175]
})

st.write("### Tableau des ventes hebdomadaires")
st.dataframe(data)

st.bar_chart(data, x="Jour", y="Ventes")
```

* **Exemple 2 :** ajouter des widgets interactifs

```python
import streamlit as st

st.title("Exemple Streamlit : Interaction")

nom = st.text_input("Entrez votre pr√©nom :")
age = st.slider("Indiquez votre √¢ge :", 0, 100, 25)

if st.button("Afficher le message"):
    st.success(f"Bonjour {nom}, vous avez {age} ans !")
```

> Exemple d‚Äôapp Snowflake/Streamlit pour explorer les trajets par jour de semaine.

```python
import streamlit as st
from snowflake.snowpark.context import get_active_session

st.title("Analyse des trajets Citi Bike")
st.write("Filtrez par jour de semaine et affichez les stations les plus utilis√©es.")

option = st.selectbox(
    "Jour de la semaine",
    ("Mon","Tue","Wed","Thu","Fri","Sat","Sun")
)

session = get_active_session()

sql = f"""
  select start_station_name as START_STATION_NAME,
         count(*) as NBTRIPS
  from CITIBIKE.PUBLIC.TRIPS
  where dayname(starttime) = '{option}'
  group by start_station_name
  order by NBTRIPS desc
  limit 10
"""
data = session.sql(sql).to_pandas()

st.subheader("Top 10 stations")
st.bar_chart(data=data, x="START_STATION_NAME", y="NBTRIPS")

sql2 = """
  select dayname(starttime) as DAY_OF_WEEK,
         count(*) as NB_TRIPS
  from CITIBIKE.PUBLIC.TRIPS
  group by dayname(starttime)
"""
data2 = session.sql(sql2).to_pandas()

st.subheader("Nombre de trajets par jour")
st.bar_chart(data=data2, x="DAY_OF_WEEK", y="NB_TRIPS")
```

## 12) Checklist de fin de lab

- [ ] DB `CITIBIKE` + table `TRIPS` cr√©√©es  
- [ ] **Stage** `citibike_trips` (S3) + **file format** `csv`  
- [ ] `COPY INTO TRIPS` ex√©cut√© (Small vs Large compar√©s)  
- [ ] Entrep√¥t d‚Äôanalyse `ANALYTICS_WH` cr√©√© et utilis√©  
- [ ] Requ√™tes d‚Äôexploration ex√©cut√©es (heure/jour)  
- [ ] DB `WEATHER` + table `JSON_WEATHER_DATA` + vue `JSON_WEATHER_DATA_VIEW`  
- [ ] Jointure m√©t√©o ‚Üî trajets ex√©cut√©e  
- [ ] `UNDROP` et **Time-Travel** test√©s  
- [ ] (Bonus) App Streamlit fonctionnelle

---

## 13) D√©pannage rapide

- **`Permission denied`** : v√©rifiez le **Role** (ACCOUNTADMIN pour le lab), et le **Context** (DB/Schema/Warehouse).  
- **`Cannot access stage`** : URL S3 correcte **avec `/` final** ? Stage au bon nom (`citibike_trips`) ?  
- **`COPY` ne charge rien** : v√©rifiez `pattern`, `file_format`, et `list @stage` pour voir les fichiers.  
- **Cr√©dits qui fondent** : repassez vos entrep√¥ts en **Small** et gardez **Auto-Suspend**.
