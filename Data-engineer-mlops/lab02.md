# Comment charger des fichiers CSV depuis un stage vers Snowflake Notebooks üìÅ

Dans cet exemple, nous allons montrer comment charger un fichier CSV depuis un stage et cr√©er une table avec Snowpark.

Commen√ßons par utiliser la commande `get_active_session` afin d‚Äôobtenir la variable de contexte de session pour travailler avec Snowpark :

```python
from snowflake.snowpark.context import get_active_session
session = get_active_session()
# Add a query tag to the session. This helps with troubleshooting and performance monitoring.
session.query_tag = {"origin":"sf_sit-is", 
                     "name":"notebook_demo_s3", 
                     "version":{"major":1, "minor":0},
                     "attributes":{"is_quickstart":2, "source":"notebook", "vignette":"csv_from_s3"}}
print(session)
```


## Cr√©er un stage externe

Nous allons maintenant cr√©er un stage externe qui r√©f√©rence des fichiers de donn√©es stock√©s en dehors de Snowflake. Dans cet exemple, les donn√©es sont stock√©es dans un bucket S3.

```sql

CREATE DATABASE IF NOT EXISTS CITIBIKE;

USE DATABASE CITBIKE;

CREATE STAGE IF NOT EXISTS CITIBIKE_STAGE 
	URL = 's3://logbrain-datalake/datasets/citibike-trips-csv/';
```

## V√©rifier les fichiers pr√©sents dans le stage

Examinons les fichiers disponibles dans le stage.

```sql
LS @CITIBIKE_STAGE;
```

## Charger le fichier CSV avec Snowpark

Nous pouvons utiliser **Snowpark DataFrameReader** pour lire le fichier CSV.

En utilisant l‚Äôoption `infer_schema = True`, Snowflake d√©duira automatiquement le sch√©ma √† partir des types de donn√©es pr√©sents dans le fichier CSV, ce qui √©vite de devoir le d√©finir manuellement.

```python
# Create a DataFrame that is configured to load data from the CSV file.
df = session.read.options({"infer_schema":True}).csv('@CITIBIKE_STAGE/trips_2018_0_0_0.csv.gz')
```

```python
df
```

## Travailler avec le DataFrame Snowpark

Une fois les donn√©es charg√©es dans un DataFrame Snowpark, nous pouvons les manipuler √† l‚Äôaide de l‚ÄôAPI Snowpark DataFrame.

Par exemple, nous pouvons calculer des statistiques descriptives sur les colonnes :

```python
df.describe()
```

## √âcrire le DataFrame dans une table Snowflake

Nous pouvons enregistrer le DataFrame dans une table nomm√©e `TRIPS` puis l‚Äôinterroger en SQL.

```python
df.write.mode("overwrite").save_as_table("TRIPS")
```

```sql
-- Preview the newly created APP_ORDER table
SELECT * from TRIPS;
```

## Relire la table dans Snowpark

Enfin, nous pouvons relire la table dans Snowpark en utilisant la syntaxe `session.table`.

```python
df = session.table("TRIPS")
df
```

## Continuer le traitement des donn√©es

√Ä partir d‚Äôici, vous pouvez continuer √† interroger et traiter les donn√©es.

```python
df.groupBy('"start_station_name"').count()
```

## Charger les donn√©es de m√©teo:


## Nettoyage des ressources

Suppression de la table et du stage cr√©√©s dans cet exemple :

```sql
-- Teardown table and stage created as part of this example
DROP TABLE TRIPS;
DROP STAGE CITIBIKE_STAGE;
DROP DATABASE CITIKIE;
```
## Conclusion

Dans cet exemple, nous avons vu comment charger un fichier CSV depuis un stage externe afin de traiter et interroger les donn√©es dans un notebook √† l‚Äôaide de Snowpark.
