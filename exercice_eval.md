
# ğŸ§Š Projet : Analyse des Offres d'Emploi LinkedIn avec Snowflake
## ğŸ¯ Objectif
Ce projet vise Ã  Ã©valuer votre capacitÃ© Ã  manipuler des donnÃ©es en utilisant Snowflake et streamlit. Vous exploiterez un ensemble de donnÃ©es provenant de LinkedIn pour effectuer des analyses pertinentes sur le marchÃ© de l'emploi.

## ğŸ“ Jeu de DonnÃ©es
Les fichiers sont disponibles dans le bucket S3 public suivant : **s3://snowflake-lab-bucket/**

Vous y trouverez les fichiers suivants :

* benefits.csv

* companies.json

* company_industries.json

* company_specialities.json

* employee_counts.csv

* industries.json

* job_industries.json

* job_postings.csv

* job_skills.csv

* salaries.csv

* skills.csv

Chaque fichier contient des informations spÃ©cifiques dÃ©taillÃ©es dans la description des colonnes.

## ğŸ› ï¸ PrÃ©requis
CrÃ©ation d'un compte Snowflake gratuit (120 jours) via ce lien si vous n'avez pas de compte.

Connaissances de base en SQL, Python et manipulation de fichiers CSV/JSON.

Utilisation exclusive de scripts pour toutes les opÃ©rations (pas d'interface graphique).

# ğŸ”§ Ã‰tapes Ã  Suivre
CrÃ©ation de la base de donnÃ©es : CrÃ©ez une base nommÃ©e **linkedin**.

CrÃ©ation d'un stage externe : Configurez un stage pointant vers le bucket S3 fourni.

DÃ©finition des formats de fichiers : SpÃ©cifiez les formats appropriÃ©s pour les fichiers CSV et JSON.

CrÃ©ation des tables : CrÃ©ez les tables correspondantes aux fichiers, en respectant les schÃ©mas fournis.

Chargement des donnÃ©es : Utilisez la commande COPY INTO pour importer les donnÃ©es depuis le stage.

Transformations nÃ©cessaires : Effectuez les transformations requises pour assurer la cohÃ©rence et l'intÃ©gritÃ© des donnÃ©es.

## ğŸ“Š Analyse des DonnÃ©es
RÃ©alisez les analyses suivantes :

1. Top 10 des titres de postes les plus publiÃ©s par industrie.

2. Top 10 des postes les mieux rÃ©munÃ©rÃ©s par industrie.

3. RÃ©partition des offres dâ€™emploi par taille dâ€™entreprise.

4. RÃ©partition des offres dâ€™emploi par secteur dâ€™activitÃ©.

5. RÃ©partition des offres dâ€™emploi par type dâ€™emploi (temps plein, stage, temps partiel).

Pour chaque analyse, crÃ©ez une visualisation appropriÃ©e en utilisant **Streamlit** directement dans Snowflake.

ğŸ“„ Livrable Attendu
Un dÃ©pÃ´t github dÃ©taillant :

1. Les commandes SQL utilisÃ©es, avec explications.

2. Le code Streamlit pour chaque visualisation, accompagnÃ© des rÃ©sultats obtenus.

3. Les problÃ¨mes rencontrÃ©s et les solutions apportÃ©es.

4. Des commentaires explicatifs pour chaque Ã©tape.

Le projet doit Ãªtre rÃ©alisÃ© en binÃ´me, avec une rÃ©partition Ã©quitable des tÃ¢ches. Les livrables identiques entre groupes seront considÃ©rÃ©s comme du plagiat et sanctionnÃ©s en consÃ©quence.

## ğŸ“¬ Soumission
Envoyez votre livrable avec intitulÃ© **MBAESG_EVALUATION_ARCHITECTURE_BIGDATA** Ã  l'adresse suivante : axel@logbrain.fr